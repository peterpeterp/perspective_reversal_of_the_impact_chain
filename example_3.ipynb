{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81e43f71",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Idea for reversal of impact chain - glaciers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89ddb5b-2c22-46a0-a487-103da639d26d",
   "metadata": {},
   "source": [
    "**Newer version: v2024-03-26**\n",
    "\n",
    "**Some additional information:**\n",
    "- we used LOWESS fits\n",
    "    - originally done to create these figures here https://github.com/lilianschuster/glacier-model-projections-until2300\n",
    "        - LOWESS fits done with the MOEPY package -> https://ayrtonb.github.io/Merit-Order-Effect/ug-08-lowess-quick-start/#quantile\n",
    "        - we computed percentiles from 1 to 99th percentile in \"1%\" steps, but if you want others, we can create other percentiles... \n",
    "- global mean warming here defined as done in IPCC AR6 WG1, that means:\n",
    "    - assume 0.69Â°C warming from preindustrial levels (1850-1900) to 1986-2005 for every GCM, then use the warming as given by individual GCMs ... \n",
    "- That means we use some glacier model data from in total two glacier models (will be updated to have three glacier models...). \n",
    "- Fits were done for all CMIP5 and CMIP6 GCMs going until 2100\n",
    "    - some glacier models have done projections with more GCMs than others .... \n",
    "    - should be sufficient to analyse if this could be a good example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a7bf7-f7e1-421b-a006-cbda383c43b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "plt.rc('font', size=18)\n",
    "\n",
    "pd_raw_data_sel = pd.read_csv('glacier_model_proj_from_GCMs_until_2100_test_RGI13-14-15_2100_v2024-03-26_OGGM_PyGEM.csv', index_col=[0])\n",
    "pd_fit = pd.read_csv('lowess_fit_from_GCMs_until_2100_RGI13-14-15_2100_OGGM_PyGEM_v2024-03-26.csv', index_col=[0])\n",
    "\n",
    "quantiles_str = []\n",
    "quantiles = np.arange(0.01,1,0.01)\n",
    "for i in quantiles:\n",
    "    _str = f'q{i:0.2f}' #.format(i)  # Format the percentile string with leading zeros\n",
    "    quantiles_str.append(_str)\n",
    "    \n",
    "# revert the columns \n",
    "pd_fit.index = pd_fit.deltaTemp.values.round(2)\n",
    "pd_fit_v = pd_fit[quantiles_str].T\n",
    "pd_fit_v['q'] = quantiles\n",
    "\n",
    "\n",
    "assert len(pd_fit.frac.unique())==1\n",
    "frac = pd_fit.frac.unique()[0].round(2)\n",
    "colors = sns.color_palette('viridis', n_colors=100)\n",
    "colors_2 = sns.color_palette('rocket_r', n_colors=12)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(121)\n",
    "\n",
    "\n",
    "\n",
    "for c,q in zip(colors,quantiles_str): \n",
    "    if q == 'q0.50':\n",
    "        sns.lineplot(data=pd_fit, x='deltaTemp', y=q, color='black', label=q, lw=3, zorder=6)\n",
    "    else:\n",
    "        sns.lineplot(data=pd_fit, x='deltaTemp', y=q, color=c, label=q, alpha = 0.8, zorder=5)\n",
    "ax = plt.gca()\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.get_legend().remove()\n",
    "leg = ax.legend([handles[0],handles[49], handles[-1]], [labels[0],labels[49], labels[-1]], title=f'LOWESS (frac={frac})\\nquantile regression')\n",
    "plt.ylabel('Remaining glacier ice mass in HMA\\n(% rel. to 2020)')\n",
    "plt.xlabel('Global mean temperature change (Â°C)')\n",
    "\n",
    "_pd_sel = pd_raw_data_sel.loc[pd_raw_data_sel.region == 'RGI13-14-15']\n",
    "_pd_sel = _pd_sel.loc[_pd_sel.year == 2100]\n",
    "sns.scatterplot(data= _pd_sel, x= 'global_temp_ch_2071-2100_preindustrial', y='rel_ice_%_2020', hue='model', zorder=10)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.get_legend().remove()\n",
    "leg2 = ax.legend(handles[-2:], labels[-2:], loc = 'lower left', title = 'glacier model\\nprojections')\n",
    "ax.add_artist(leg)\n",
    "for j,t in enumerate(np.arange(1,6.5,0.5)):\n",
    "    plt.axvline(t, lw=0.5,  color=colors_2[j])\n",
    "\n",
    "plt.subplot(122)\n",
    "for j,t in enumerate(np.arange(1,6.5,0.5)):\n",
    "    sns.scatterplot(data=pd_fit_v, x= 'q', y= t, color=colors_2[j], label=f'{t}Â°C')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1,1), title= 'GMT')\n",
    "plt.xlabel('quantile')\n",
    "plt.ylabel('Remaining glacier ice mass in HMA\\n(% rel. to 2020)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42b9a34-fbcc-4559-ad4c-1fe856c9f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_fit_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6615c07a-0579-4990-8552-8e78aa6cc810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "# for 1.5\n",
    "pd_fit_v_sel = pd_fit_v[1.5]\n",
    "\n",
    "# Assuming you have a list of quantile values called quantile_values\n",
    "quantile_values = np.array(pd_fit_v_sel.values)\n",
    "\n",
    "# Estimate the density function using kernel density estimation\n",
    "kde = gaussian_kde(quantile_values)\n",
    "\n",
    "# Generate points to plot the estimated density function\n",
    "x = np.linspace(np.min(quantile_values), np.max(quantile_values), 1000)\n",
    "density_estimate = kde(x)\n",
    "\n",
    "# Plot the estimated density function\n",
    "plt.plot(x, density_estimate)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Estimated Probability Density Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff45b3-72ba-48a7-8405-b5bd15ac09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_fit_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842ae709-11c0-498a-a95c-40d534a214db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=pd_fit_v[np.arange(1.5,5,0.5)], palette=sns.color_palette('rocket_r', n_colors=7), legend=True, cut=0,\n",
    "           fill=True, alpha=0.5,lw=2)\n",
    "plt.xlabel('Remaining glacier ice mass in HMA\\n(% rel. to 2020)')\n",
    "ax = plt.gca()\n",
    "leg = ax.get_legend()\n",
    "#handles, labels = ax.get_legend_handles_labels()\n",
    "leg.set_bbox_to_anchor((1.4,1))\n",
    "leg.set_title('GMT (Â°C)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996cec39-4088-410d-a41c-e169aedc44dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Assuming corrected q and d arrays of the same length\n",
    "q = np.linspace(0.01, 0.991, 99)  # Quantiles from 0.01 to 0.99\n",
    "d = pd_fit_v_sel.values # np.linspace(1, 99, 99)  # Corresponding data values, adjust as per your data\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(q, d, marker='o')\n",
    "plt.title('Frequency Distribution from Quantiles')\n",
    "plt.xlabel('Quantiles')\n",
    "plt.ylabel('Data Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f521ad",
   "metadata": {},
   "source": [
    "### added by peter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d5d4fea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/peterp/projects/reversal_perspective/reversal_perspective/example_3.ipynb Cell 10\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/peterp/projects/reversal_perspective/reversal_perspective/example_3.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/peterp/projects/reversal_perspective/reversal_perspective/example_3.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/peterp/projects/reversal_perspective/reversal_perspective/example_3.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39mrc(\u001b[39m'\u001b[39m\u001b[39mfont\u001b[39m\u001b[39m'\u001b[39m, size\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/peterp/projects/reversal_perspective/reversal_perspective/example_3.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m matplotlib\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39mfigure.figsize\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m (\u001b[39m4\u001b[39m,\u001b[39m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import xarray as xr\n",
    "import collections\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "plt.rc('font', size=12)\n",
    "matplotlib.rcParams['figure.figsize'] = (4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265914df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_fit = pd.read_csv('lowess_fit_from_GCMs_until_2100_RGI13-14-15_2100_OGGM_PyGEM_GloGEM_v2024-03-26.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9647338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store pd_fit in an xarray\n",
    "quantiles = xr.DataArray(pd_fit_v.T.values[:-1], dims=['gmt','q'], coords=dict(gmt=pd_fit_v.columns.values[:-1], q=[float(s[1:]) for s in pd_fit_v.index.values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8562bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_greater_at_gmt(g, thresh):\n",
    "    '''\n",
    "    returns the probability of keeping the threshold amount of glacier at given GMT g\n",
    "    '''\n",
    "    y = quantiles.sel(gmt=g, method='nearest')\n",
    "    return 1 - quantiles.q.values[np.abs(y - thresh).argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d270d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmt_axis = np.arange(1,4,0.1)\n",
    "p = np.array([prob_greater_at_gmt(g, 50) for g in gmt_axis])\n",
    "plt.plot(gmt_axis, p)\n",
    "plt.xlabel('GMT')\n",
    "plt.ylabel('probability of keeping\\n50% of glaciers')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da4b38",
   "metadata": {},
   "source": [
    "GMT:\n",
    "1986-2005 vs 1850-1900 \n",
    "1986-2005 should be 0.69K warmer than preindustrial\n",
    "gmt -= gmt.loc[1986-2005].mean() + 0.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad2221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_greater_in_scenario(scen, thresh):\n",
    "    '''\n",
    "    returns the probability of crossing thresh in given scenario\n",
    "    '''\n",
    "    # get all gmt values in 2100 from the 2237 runs\n",
    "    # bin GMT in 0.1 K steps\n",
    "    # and count occurences in bins\n",
    "    counter = collections.Counter(gmt.loc[scen].round(1).values)\n",
    "    p = np.array([])\n",
    "    # for each bin add the probability of crossing thresh at GMT level \"count\"-times\n",
    "    for g,count in counter.items():\n",
    "        p = np.append(p, [prob_greater_at_gmt(g, thresh)]*count)\n",
    "    return p.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f659e758",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c11b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmt = xr.open_dataset(f'gmt_in_{year}.nc')['gmt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6477b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the probability of keeping X% of the glacier for all 1500 scenarios\n",
    "p_greater = xr.DataArray(dims=['scenario', 'thresh'], coords=dict(scenario=gmt.scenario.values, thresh=np.arange(40,70,10,'int')))\n",
    "for thresh in p_greater.thresh.values:\n",
    "    for scen in p_greater.scenario.values:\n",
    "        p_greater.loc[scen, thresh] = prob_greater_in_scenario(scen, thresh)\n",
    "xr.Dataset({'p_greater':p_greater}).to_netcdf(f'p_greater_in_{year}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c359f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_greater = xr.open_dataset(f'p_greater_in_{year}.nc')['p_greater']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c432652",
   "metadata": {},
   "outputs": [],
   "source": [
    "for thresh in p_greater.thresh.values[:]:\n",
    "    plt.scatter(gmt.mean('run'),p_greater.loc[:,thresh], label=f'{thresh}')\n",
    "plt.xlabel('GMT averaged over runs of the scenario')\n",
    "plt.ylabel('probability of only\\n... of the glacier remaining')\n",
    "plt.legend(title='remaining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846caa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify scenarios for which there is a 90% chance of keeping 40% of the glaciers\n",
    "boundary_scenarios = p_greater.scenario[np.abs(p_greater.loc[:,40] - 0.90) < 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7529fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify scenarios for which there is a 90% chance of keeping 50% of the glaciers\n",
    "boundary_scenarios = p_greater.scenario[np.abs(p_greater.loc[:,50] - 0.80) < 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b6ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMT distributions for boundary scenarios in 2100\n",
    "fig,ax = plt.subplots(nrows=1, figsize=(4,3))\n",
    "for scen in boundary_scenarios:\n",
    "    sns.kdeplot(gmt.loc[scen], color='gray', linewidth=0.3)\n",
    "    ax.axvline(gmt.loc[scen].median(), color='gray', linewidth=0.3)\n",
    "ax.set_xlabel('GMST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015fa46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fair emissions\n",
    "emissions = pd.read_table('../Tier2_scenarios_emissions.csv', sep=',')\n",
    "co2 = emissions.loc[(emissions.Variable == 'Emissions|CO2')]\n",
    "co2 = xr.DataArray(co2.iloc[:,5:].values, dims=['scen','year'], coords=dict(scen=co2.Scenario, year=np.array(co2.columns[5:], 'int')))\n",
    "ch4 = emissions.loc[(emissions.Variable == 'Emissions|CH4')]\n",
    "ch4 = xr.DataArray(ch4.iloc[:,5:].values, dims=['scen','year'], coords=dict(scen=ch4.Scenario, year=np.array(ch4.columns[5:], 'int')))\n",
    "cum_co2 = (co2.loc[:,2020:2100].rolling(year=2).sum() * 0.5 * 10).sum('year') / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8ddecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select scenarios that stabilize in 2100\n",
    "# -> no overshoot efore 2100\n",
    "# -> potential for keeping the glacier mass later on as well\n",
    "selected_boundary_scenarios = boundary_scenarios[(co2.loc[boundary_scenarios].loc[:,2030] <= co2.loc[boundary_scenarios].loc[:,2020])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d9426",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmt_median = xr.open_dataset('gmt_median.nc')['gmt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1735fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,axes = plt.subplots(nrows=1, ncols=2, figsize=(8,3))\n",
    "axes[1].axhline(0, color='k')\n",
    "for scenarios, color in zip([boundary_scenarios, selected_boundary_scenarios], ['gray','orange']):\n",
    "    for scen in scenarios.values:\n",
    "        y = gmt_median.loc[scen,:2100]\n",
    "        axes[0].plot(y.year, y, label=scen, color=color)\n",
    "        y = co2.loc[scen,:2100] / 1000\n",
    "        axes[1].plot(y.year, y, color=color)\n",
    "    \n",
    "axes[0].set_ylabel('GMST [K]')\n",
    "axes[1].set_ylabel('CO2 emissions [Gt/yr]')\n",
    "plt.tight_layout() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97336d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cumulative CO2 emissions until 2100 in the orange scenario\n",
    "CO2_budget = cum_co2.loc[selected_boundary_scenarios].values.mean()\n",
    "CO2_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7c80c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_co2.loc[selected_boundary_scenarios].values.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f71a3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_gmlnet",
   "language": "python",
   "name": "py_gmlnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
